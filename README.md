# Scrapy Parser PEP

## Описание
Проект асинхронного парсера позволяет получать список всех PEP для Python,
информацию о статусах и их количестве, и записывает полученную информацию в файл.

## Парсинг документов PEP
Асинхронный парсер собирающий данные о Python Enhancement Proposals (PEP) с сайта `https://www.python.org/`.
Парсер собирает номер, название, статус о PEP и сохраняет
информацию в формате `.csv`:
* Список PEP [номер, название, статус];
* Подсчитывает общее количество каждого статуса и количество всех статусов.

## Технологии проекта
* Python — высокоуровневый язык программирования.
* Scrapy — фреймворк для парсинга веб сайтов.

## Запуск проекта:
Клонировать репозиторий и перейти в него в командной строке:

```
git clone https://github.com/Theivlev/scrapy_parser_pep.git
```

Создать и активировать виртуальное окружение:
```
python -m venv env
```

```
source env/bin/activate
```

Установить зависимости из файла requirements.txt:
```
python -m pip install --upgrade pip
```

```
pip install -r requirements.txt
```

## Запуск парсера
```
scrapy crawl pep
```

Автор: [Алексей Ивлев](https://github.com/Theivlev)